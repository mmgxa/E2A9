{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2 - Assign 9_P1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uluHLDSMyTzz"
      },
      "source": [
        "# Recall, Precision, and F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvAuAICLnS-t"
      },
      "source": [
        "# Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "324fXg1BnVqv"
      },
      "source": [
        "For this task, we will use the assignment from week 3 i.e. MNIST (without the addition task). Also, to make the interpretation of the scores easier, we will turn it into a binary classification problem: is the output class/digit even (0,2,4,6,8) or odd (1,3,5,7,9) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmA-HIQJtl6D",
        "outputId": "7c9c3d92-be3e-4cb7-bb8e-9b2504c035fe"
      },
      "source": [
        "!pip install tableprint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tableprint in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tableprint) (0.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from tableprint) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qSDz6ovsA4t"
      },
      "source": [
        "def score(targets, predictions):\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for target, prediction in zip(targets, predictions):\n",
        "    if target == 1:\n",
        "      if prediction ==1:\n",
        "        tp += 1\n",
        "      else:\n",
        "        fn += 1\n",
        "    else:\n",
        "      if prediction ==1:\n",
        "        fp += 1\n",
        "      else:\n",
        "        tn += 1\n",
        "  return tp, tn, fp, fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3HSYE0j10gN"
      },
      "source": [
        "# Sanity Check\n",
        "After tabulating the result, we see that the calculating accuracy using our `score`  function matches the results from our previous work (also tabulated!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb5cCNGSucOV"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bq9xYnuubGi"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "import tableprint as tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ssymKcCujFZ"
      },
      "source": [
        "## Loading the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tryfs0quulRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32cf979-c871-44a9-d817-3ffdfff7d645"
      },
      "source": [
        "train_dataset = torchvision.datasets.MNIST(\n",
        "                    root='.',\n",
        "                    train=True,\n",
        "                    transform=transforms.ToTensor(), \n",
        "                    download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "                    root='.',\n",
        "                    train=False,\n",
        "                    transform=transforms.ToTensor(),\n",
        "                    download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyFEJpkduuGS"
      },
      "source": [
        " ## Turn targets into binary class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i213RXOSupry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fb84f1-8052-4fd8-a3b6-af933def4ae2"
      },
      "source": [
        "def ev(x):\n",
        "  if x%2 == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "train_dataset.targets.apply_(ev)\n",
        "test_dataset.targets.apply_(ev)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0,  ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHjDjFwko8iz",
        "outputId": "ff5ef040-6797-4b46-99da-4cd4e7b1fa73"
      },
      "source": [
        "print(train_dataset.targets.max(), train_dataset.targets.min())\n",
        "print(test_dataset.targets.max(), test_dataset.targets.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1) tensor(0)\n",
            "tensor(1) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_69MdhcvFOS"
      },
      "source": [
        "## Re-creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Ui8J4MvG39"
      },
      "source": [
        "# Flattens the MNIST images\n",
        "train_x = train_dataset.data.reshape(60000, 784).float()\n",
        "test_x = test_dataset.data.reshape(10000, 784).float()\n",
        "\n",
        "# Creats the Dataset with the modified targets\n",
        "train_ds = torch.utils.data.TensorDataset(train_x, train_dataset.targets)\n",
        "test_ds = torch.utils.data.TensorDataset(test_x, test_dataset.targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-F0OAlBvIfb"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpqFLHofvL-A"
      },
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                        dataset=train_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True\n",
        "                        )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                        dataset=test_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=False # Not necessary!\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBBXOpDsvOVm"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgOtM7hEvPhu"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear1 = nn.Linear(784, 30) # Flattened MNIST as Input: 28 * 28\n",
        "        self.relu = nn.ReLU()\n",
        "        self.selu = nn.SELU()\n",
        "        self.linear2 = nn.Linear(30, 30)\n",
        "        self.linear3 = nn.Linear(30,2) # 2 Classes for The Output: 0-1\n",
        "\n",
        "            \n",
        "    def forward(self, Xa):\n",
        "\n",
        "        out = self.linear1(Xa)\n",
        "        out = self.selu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.selu(out)\n",
        "        out = self.linear3(out)\n",
        "        out = self.selu(out)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "# Instantiate the Model\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXu7e9qSvUQx"
      },
      "source": [
        "## Move Model to GPU (Required Condition by Assignment!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYPA-pEIvaUS",
        "outputId": "0c4b1138-c8c8-4ea5-9cab-744842f8bf52"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (linear1): Linear(in_features=784, out_features=30, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (selu): SELU()\n",
              "  (linear2): Linear(in_features=30, out_features=30, bias=True)\n",
              "  (linear3): Linear(in_features=30, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRI8imRdvcHv"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa4iXVqLvdpW",
        "outputId": "91f15353-f5b7-4a1f-f5d7-2ba5f0267ccb"
      },
      "source": [
        "summary(model, [(1,784)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 30]          23,550\n",
            "              SELU-2                [-1, 1, 30]               0\n",
            "            Linear-3                [-1, 1, 30]             930\n",
            "              SELU-4                [-1, 1, 30]               0\n",
            "            Linear-5                 [-1, 1, 2]              62\n",
            "              SELU-6                 [-1, 1, 2]               0\n",
            "================================================================\n",
            "Total params: 24,542\n",
            "Trainable params: 24,542\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.09\n",
            "Estimated Total Size (MB): 0.10\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO9dQJJfvfPc"
      },
      "source": [
        "## Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o79IzzV7vhae"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6ClCvKqwO4X"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpql5R5EwQEd",
        "outputId": "6786aafb-6aaf-4175-c2f3-a4e2ea015343"
      },
      "source": [
        "\n",
        "n_epochs = 20\n",
        "\n",
        "\n",
        "table_context = tp.TableContext(headers=['epoch', 'Train Acc', 'Train Loss', 'Valid Acc', 'Valid Loss', 'Val Acc', 'Valid Rec', 'Valid Prec', 'Valid F1'])\n",
        "table_context.__enter__()\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = []\n",
        "    n_correct = 0.\n",
        "    n_total = 0.\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "\n",
        "        # Move data to GPU\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        # zero the gradient\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        output = model(inputs)\n",
        "        loss = loss_fn(output, targets)\n",
        "\n",
        "        # get predictiona\n",
        "        _, prediction= torch.max(output, 1)\n",
        "\n",
        "        # update counts\n",
        "        n_correct += (prediction == targets).sum().item()\n",
        "        n_total += targets.shape[0]\n",
        " \n",
        "        # backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "        \n",
        "    train_loss = np.mean(train_loss)\n",
        "    train_acc = n_correct / n_total * 100\n",
        "\n",
        "    \n",
        "    test_loss = []\n",
        "    n_correct = 0.\n",
        "    n_total = 0.\n",
        "    tpt, tnt, fpt, fnt = 0, 0, 0, 0\n",
        "    for inputs, targets in test_loader:\n",
        "\n",
        "        # Move data to GPU\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        # forward pass\n",
        "        output = model(inputs)\n",
        "        loss = loss_fn(output, targets)\n",
        "                \n",
        "         # get predictions\n",
        "        _, prediction = torch.max(output, 1) \n",
        "        \n",
        "        \n",
        "        # update counts\n",
        "        n_correct += (prediction == targets).sum().item()\n",
        "\n",
        "        n_total += targets.shape[0]\n",
        "\n",
        "        test_loss.append(loss.item())\n",
        "        tp, tn, fp, fn = score(prediction, targets)\n",
        "        tpt += tp\n",
        "        tnt += tn\n",
        "        fpt += fp\n",
        "        fnt += fn\n",
        "        \n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_acc = n_correct / n_total * 100\n",
        "    a = (tpt+tnt) / (tpt+tnt +fpt +fnt)\n",
        "    r = tpt / (tpt + fnt)\n",
        "    p = tpt / (tpt + fpt)\n",
        "    f1 = 2 * (p*r)/(p+r)\n",
        "    table_context([epoch+1, train_acc, train_loss, test_acc, test_loss, a, r, p, f1])\n",
        "table_context.__exit__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "╭─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────╮\n",
            "│       epoch │   Train Acc │  Train Loss │   Valid Acc │  Valid Loss │     Val Acc │   Valid Rec │  Valid Prec │    Valid F1 │\n",
            "├─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┤\n",
            "│           1 │      90.043 │     0.24497 │       96.83 │    0.098878 │      0.9683 │     0.95788 │     0.97868 │     0.96817 │\n",
            "│           2 │      96.978 │    0.091356 │       96.99 │    0.098771 │      0.9699 │     0.97165 │     0.96711 │     0.96938 │\n",
            "│           3 │       97.54 │    0.072313 │       97.83 │    0.072959 │      0.9783 │     0.98258 │      0.9732 │     0.97787 │\n",
            "│           4 │      97.878 │    0.062474 │       98.02 │    0.066016 │      0.9802 │     0.98088 │     0.97889 │     0.97988 │\n",
            "│           5 │      98.103 │    0.057452 │       97.29 │    0.082461 │      0.9729 │     0.98198 │     0.96265 │     0.97222 │\n",
            "│           6 │      98.317 │    0.051321 │       98.09 │    0.063521 │      0.9809 │     0.98544 │     0.97564 │     0.98052 │\n",
            "│           7 │      98.402 │    0.047289 │       97.48 │    0.085557 │      0.9748 │     0.98586 │     0.96265 │     0.97412 │\n",
            "│           8 │      98.535 │    0.042866 │       98.17 │    0.059476 │      0.9817 │     0.97919 │     0.98376 │     0.98147 │\n",
            "│           9 │       98.55 │    0.041795 │       98.32 │    0.055634 │      0.9832 │     0.97694 │     0.98924 │     0.98305 │\n",
            "│          10 │      98.732 │    0.037779 │        98.1 │    0.067117 │       0.981 │     0.98228 │     0.97909 │     0.98068 │\n",
            "│          11 │      98.762 │    0.036443 │       97.77 │    0.068822 │      0.9777 │     0.96722 │     0.98823 │     0.97761 │\n",
            "│          12 │      98.843 │    0.035164 │       97.98 │    0.084554 │      0.9798 │     0.98581 │       0.973 │     0.97936 │\n",
            "│          13 │      98.942 │    0.030886 │       98.19 │    0.059014 │      0.9819 │     0.98448 │     0.97868 │     0.98157 │\n",
            "│          14 │      99.002 │    0.029302 │       98.18 │    0.066869 │      0.9818 │     0.98349 │      0.9795 │     0.98149 │\n",
            "│          15 │      98.982 │    0.029094 │       98.15 │    0.066012 │      0.9815 │     0.97821 │     0.98437 │     0.98128 │\n",
            "│          16 │      99.092 │    0.026849 │       98.13 │    0.068708 │      0.9813 │     0.97763 │     0.98457 │     0.98109 │\n",
            "│          17 │      99.077 │    0.027501 │       98.16 │    0.064794 │      0.9816 │     0.98388 │     0.97868 │     0.98127 │\n",
            "│          18 │      99.165 │    0.024696 │       98.31 │     0.07599 │      0.9831 │     0.97944 │      0.9864 │     0.98291 │\n",
            "│          19 │       99.13 │    0.024841 │       98.26 │    0.084453 │      0.9826 │     0.98039 │     0.98437 │     0.98237 │\n",
            "│          20 │      99.225 │    0.024032 │        98.4 │    0.083581 │       0.984 │     0.98103 │      0.9866 │     0.98381 │\n",
            "╰─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────╯\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}